{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f87867-ef88-4ea3-8456-2e4aedf0a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Majid\\anaconda3\\envs\\LLM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import partial\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623513eb-2dbd-402e-b382-5cb7d78850ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n",
      "First entry: {'instruction': 'Translate the following sentence into French.', 'input': 'Where is the nearest restaurant?', 'output': 'Où est le restaurant le plus proche?'}\n"
     ]
    }
   ],
   "source": [
    "# Download and open the instruction Dataset.\n",
    "def download_and_load_file(file_path, url, is_jsonl=False):\n",
    "    # Download if not exists\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode('utf-8')\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    # Load file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        if is_jsonl:  # JSON Lines format\n",
    "            data = [json.loads(line) for line in file if line.strip()]\n",
    "        else:  # Standard JSON array\n",
    "            data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = 'instruction-data.json'\n",
    "url = 'https://raw.githubusercontent.com/majidarasteh/Large-Language-Model_LLM/refs/heads/main/Resources/instruction-data.json'\n",
    "\n",
    "data = download_and_load_file(file_path, url, is_jsonl=False)  # set True if file is JSONL\n",
    "print('Number of entries:', len(data))\n",
    "print('First entry:', data[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ded968-e751-428d-a985-34b3765d3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * Convert a single dataset entry into a text prompt suitable for instruction-following models.\n",
    "    * The function expects an entry dictionary with this structure:\n",
    "        entry = {\n",
    "                'instruction': 'Translate to French',  # Required\n",
    "                'input': 'Hello world',                # Optional\n",
    "                'output': 'Bonjour le monde'           # Not used in this function\n",
    "            }\n",
    "    * The function returns a string that combines the instruction and input into a standard prompt format.\n",
    "\n",
    "    * Prepares instruction-following prompt in a consistent format\n",
    "      - Includes \"instruction\" always.\n",
    "      - Includes \"input\" only if it exists\n",
    "      - Output is a single string ready for tokenization\n",
    "\"\"\"\n",
    "\n",
    "def format_input(entry):\n",
    "    # Base instruction template\n",
    "    instruction_text = (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        f\"\\n# Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # Add input section only if it exists\n",
    "    input_text = f\"\\n# Input:\\n{entry['input']}\" if entry.get(\"input\") else \"\"\n",
    "\n",
    "    # The function returns a string that combines the instruction and input into a standard prompt format.\n",
    "    return instruction_text + input_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d2560b-012f-4518-bc90-f14a44bb45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. \n",
      "# Instruction:\n",
      "Translate the following sentence into French.\n",
      "# Input:\n",
      "Where is the nearest restaurant?\n",
      "# Response:\n",
      "Où est le restaurant le plus proche?\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    * This code is preparing an input-output pair for instruction fine-tuning a language model.\n",
    "    * data[6] → selects the 7th entry in your dataset (Python is 0-indexed).\n",
    "    * format_input() → formats it into the instruction prompt, like we discussed earlier.\n",
    "\"\"\"\n",
    "\n",
    "model_input = format_input(data[6])\n",
    "desired_response = f'\\n# Response:\\n{data[6]['output']}'\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32aa2cdf-af01-47c2-80d1-9861db2380b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    * This block is used to split your dataset into training, validation, and test sets.\n",
    "    * len(data) → total number of examples in your dataset.\n",
    "    * train_portion → 85% of the dataset for training.\n",
    "    * test_portion → 10% of the dataset for testing.\n",
    "    * val_portion → whatever is left (≈5%) for validation.\n",
    "    * Using int() ensures we get whole numbers (no fractional indices).\n",
    "\n",
    "    * |---------- train_portion ----------|--- test_portion ---|--- val_portion ---|\n",
    "\n",
    "    * Shuffle the dataset to avoid order bias.\n",
    "\"\"\"\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "random.seed(123)       # ensures that every time you run this, you get the same shuffle.\n",
    "random.shuffle(data)   # randomly rearranges the elements of data in place.\n",
    "\n",
    "\n",
    "train_portion = int(len(data) * 0.85)  \n",
    "test_portion = int(len(data) * 0.1)    \n",
    "val_portion = len(data) - train_portion - test_portion   \n",
    "\n",
    "train_data = data[:train_portion]                            # selects the first 85% of the data.\n",
    "test_data = data[train_portion:train_portion + test_portion] # selects the next 10%.\n",
    "val_data = data[train_portion + test_portion:]               # selects the remaining 5%.\n",
    "\n",
    "print('Training set length:', len(train_data))\n",
    "print('Validation set length:', len(val_data))\n",
    "print('Test set length:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2203a7fd-38b5-4d9c-88a0-a4b9e9733aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This code defines a custom PyTorch Dataset for instruction fine-tuning a language model like GPT-2.\n",
    "    * tokenizer → GPT-2 tokenizer (or similar) to convert text into token IDs.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data         # A list of dataset entries, each entry is a dictionary like. \n",
    "        self.encoded_texts = []  # Stores tokenized sequences for each entry.\n",
    "        for entry in data:  \n",
    "            instruction_plus_input = format_input(entry)         # formats the instruction and optional input into a prompt string.\n",
    "            response_text = f'\\n# Response:\\n{entry['output']}'  # adds the correct answer (output) under # Response:.\n",
    "            full_text = instruction_plus_input + response_text   # concatenates prompt + response into one text string.\n",
    "            self.encoded_texts.append(                           # converts the full text into a list of token IDs that the model\n",
    "                tokenizer.encode(full_text)                      # Each token ID corresponds to a token in the GPT-2 vocabulary.\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):            # Returns the tokenized sequence at the specified index.\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):                       # Returns the total number of examples in the dataset.\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae240a7f-512c-4452-a8f6-2499de348f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This function is a custom batching function for PyTorch’s DataLoader. Its job is to:\n",
    "        - Take individual encoded sequences from your InstructionDataset.\n",
    "        - Pad them so they can form a uniform batch.\n",
    "        - Prepare input and target tensors for causal language modeling (next-token prediction)\n",
    "\"\"\"\n",
    "\n",
    "def custom_collate_fn(batch,                    # a list of items returned by Dataset.__getitem__ (each is a list of token IDs).\n",
    "                      pad_token_id=50256,       # GPT-2’s default \"padding\" token → actually <|endoftext|>.\n",
    "                      ignore_index=-100,        # tokens with this value are ignored by torch.nn.CrossEntropyLoss.\n",
    "                      allowed_max_length=None,  #  optional max sequence length for truncation.\n",
    "                      device='cpu'):            # move tensors to CPU or GPU.\n",
    "    \n",
    "    batch_max_length = max(len(item)+1 for item in batch)   # Finds the longest sequence in the batch.\n",
    "    inputs_lst, targets_lst = [], []                        # Lists to collect padded input and target tensors.\n",
    "\n",
    "    for item in batch:               # For each sequence in the batch:\n",
    "        new_item = item.copy()       # Make a copy\n",
    "        new_item += [pad_token_id]   # Append one <pad> at the end (needed because we’ll shift inputs and targets).\n",
    "\n",
    "        \n",
    "        # Pad the sequence with enough <pad> tokens so it matches the batch’s max length.\n",
    "        padded = (                 \n",
    "            new_item + [pad_token_id] *         \n",
    "            (batch_max_length - len(new_item))  \n",
    "        )\n",
    "\n",
    "        # This is the classic next-token prediction setup.\n",
    "        inputs = torch.tensor(padded[:-1])     # all tokens except the last (e.g., [The, cat, sat]) \n",
    "        targets = torch.tensor(padded[1:])     # all tokens except the first (e.g., [cat, sat, on])  \n",
    "\n",
    "        mask = targets == pad_token_id            \n",
    "        indices = torch.nonzero(mask).squeeze()   # Find positions of <pad> tokens in targets.\n",
    "        if indices.numel() > 1:                   # Keep the first pad as is, but set the rest to ignore_index.\n",
    "            targets[indices[1:]] = ignore_index   \n",
    "\n",
    "        # Optionally truncate sequences to a fixed length (helps GPU memory).\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]  \n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        # Store padded tensors for the batch.\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    \"\"\"\n",
    "        * Stack lists into tensors of shape\n",
    "          - inputs_tensor: [batch_size, seq_len]\n",
    "          - targets_tensor: [batch_size, seq_len]\n",
    "          - Move to CPU/GPU.\n",
    "    \"\"\"\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f4f96d-c390-4928-8151-d6929596d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4,     5,     6,     7],\n",
      "        [    8,     9,    10,    11,    12, 50256, 50256, 50256],\n",
      "        [   13,    14, 50256, 50256, 50256, 50256, 50256, 50256]]) \n",
      "\n",
      "tensor([[    1,     2,     3,     4,     5,     6,     7, 50256],\n",
      "        [    9,    10,    11,    12, 50256,  -100,  -100,  -100],\n",
      "        [   14, 50256,  -100,  -100,  -100,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "\n",
    "inputs_1 = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "inputs_2 = [8, 9, 10, 11, 12]\n",
    "inputs_3 = [13, 14]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs,\"\\n\")\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b949281-c0cb-4eae-bf9b-558caed7b48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')     \n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aacc626e-37a4-461a-a8b0-2034b8e3fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "\n",
    "\"\"\"\n",
    "    * Partial is a Python utility that lets you pre-fill some arguments of a function.\n",
    "    - and reating a new function with fewer required parameters.\n",
    "\n",
    "    * Example: \n",
    "    * def multiply(a, b):\n",
    "          return a * b\n",
    "      double = partial(multiply, b=2)   # now double(x) means multiply(x, 2)\n",
    "      print(double(5))  # 10\n",
    "\n",
    "      * Now, customized_collate_fn behaves like custom_collate_fn,\n",
    "        but you don’t need to provide device or allowed_max_length every time — they are fixed.\n",
    "\"\"\"\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,            # always use your chosen device (cpu or cuda)\n",
    "    allowed_max_length=1024   # always truncate to max 1024 tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fcdc54-51dd-4739-8e48-a0ad44e7fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set pad_token to eos_token.\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT-2 model\n",
    "\n",
    "# Choose model size: \"gpt2\", \"gpt2-medium\", \"gpt2-large\", or \"gpt2-xl\"\n",
    "model_name = \"gpt2-medium\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Set padding token\n",
    "\"\"\"\n",
    "    Problem: Original GPT-2 doesn't have a dedicated padding token\n",
    "    Solution: Use the end-of-sequence (<|endoftext|>) token for padding\n",
    "    Why: Needed for batch processing with sequences of different lengths\n",
    "\"\"\"\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Use end-of-sequence token for padding\n",
    "    print(\"Set pad_token to eos_token.\")\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7796859f-3775-4863-ae2b-daf6870e4972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 1024)\n",
      "    (wpe): Embedding(1024, 1024)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=3072, nx=1024)\n",
      "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
      "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc9e386-55ef-4a06-bc93-1ef41a710fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. \n",
      "# Instruction:\n",
      "Convert the following verb to its gerund form: 'write'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])  # Transforms a raw dataset entry into Alpaca-style prompt text.\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acfc3999-622a-4a0a-a3e7-8c2c69cb96cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. \n",
      "# Instruction:\n",
      "Convert the following verb to its gerund form: 'write'  - This is a verb that is preceded by a space and is followed by the gerund\n"
     ]
    }
   ],
   "source": [
    "# Test the original GPT-2 model\n",
    "# Encode input text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate output (no gradients needed for inference)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=50,       # total length of output\n",
    "        num_return_sequences=1, \n",
    "        do_sample=True,      # sampling for more variety\n",
    "        temperature=0.8      # controls randomness\n",
    "    )\n",
    "\n",
    "# Decode and print\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260d2812-2112-4a87-84f4-fcaa36b22873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * It’s setting up your PyTorch DataLoaders for training, validation, and testing.\n",
    "\"\"\"\n",
    "\n",
    "num_workers = 0   # number of subprocesses used for data loading. 0 means everything runs in the main process.\n",
    "batch_size = 8    # each training step will use 8 examples at a time.\n",
    "\n",
    "torch.manual_seed(123) # fixes randomness so that shuffling, batching, and any other random operation is reproducible.\n",
    "\n",
    "# This DataLoader gives you randomized training batches, ready for fine-tuning.\n",
    "# wraps the raw training data into a Dataset that tokenizes each example.\n",
    "train_dataset = InstructionDataset(train_data, tokenizer) \n",
    "train_loader = DataLoader(              # Creates an iterator that yields batches from the dataset.\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,              # 8 examples per batch.\n",
    "    collate_fn=customized_collate_fn,   # special function that pads and batches sequences.\n",
    "    shuffle=True,                       # shuffles dataset every epoch (important for training).\n",
    "    drop_last=True,                     # drops the last batch if it’s smaller than 8 (keeps consistent batch sizes).\n",
    "    num_workers=num_workers             # single-process data loading.\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "190d7d73-9e3a-4533-82f0-88f62bcfd8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n"
     ]
    }
   ],
   "source": [
    "print('Train loader:')\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92eded37-fb9c-42af-bd60-43f6e70e1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * Calculates loss for a single batch.\n",
    "    * This function is the \"engine\" of learning. \n",
    "    * The optimizer will use this loss value to adjust every single weight in the model.\n",
    "\"\"\"\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "\n",
    "    \"\"\"\n",
    "        * Move Data to the Correct Device:\n",
    "          - This ensures the data is on the same hardware as the model (e.g., both on the GPU or both on the CPU).\n",
    "          - This is necessary for the upcoming computations.\n",
    "          \n",
    "        * input_batch: The token IDs for the input sequence (e.g., [\"Every\", \"effort\", \"moves\"]).\n",
    "        * target_batch: The token IDs for the target sequence, which is the input shifted by one (e.g., [\"effort\", \"moves\", \"you\"]). \n",
    "          - These are the \"correct answers.\"\n",
    "    \"\"\"\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    \"\"\"\n",
    "        * Forward Pass: Get Model Predictions:\n",
    "          - The model processes the input_batch and produces its predictions.\n",
    "          - logits: The model's raw, unnormalized output. Its shape is [batch_size, num_tokens, vocab_size].\n",
    "          - Example: \n",
    "              - For a batch of 2 sequences, each with 3 tokens, and a vocabulary of 50,257 words, the shape is [2, 3, 50257].\n",
    "        * For each of the 6 token positions (2 sequences * 3 tokens), the model outputs 50,257 scores.\n",
    "          - One for each possible next word in the vocabulary.\n",
    "    \"\"\"\n",
    "    output = model(input_batch)\n",
    "    logits = output.logits\n",
    "    \n",
    "    \"\"\"\n",
    "        * Calculate the Loss (The Most Important Step)\n",
    "        * Flatten the tensors for cross-entropy calculation\n",
    "          - logits.flatten(0, 1): This reshapes the logits from [2, 3, 50257] to [6, 50257]. \n",
    "             - It combines the batch and sequence dimensions.\n",
    "             \n",
    "          - target_batch.flatten(): This reshapes the targets from [2, 3] to [6].\n",
    "             - It creates a simple list of the 6 correct answer token IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Flatten for cross_entropy: [B*seq_len, vocab_size]\n",
    "    \"\"\"\n",
    "        Example:\n",
    "            - B = 2, seq_len = 3, vocab_size = 5\n",
    "            - logits.shape = [2, 3, 5]\n",
    "            - target_batch.shape = [2, 3]\n",
    "    \"\"\"\n",
    "    \n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    targets_flat = target_batch.view(-1)  # [B*seq_len]\n",
    "    \n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits_flat, targets_flat\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "074fe610-ee54-49b3-8ac0-2256dbf12398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This function calculates the average loss of a model over one or more batches of data from a DataLoader.\n",
    "\"\"\"\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"Calculates average loss over multiple batches.\"\"\"\n",
    "    total_loss = 0.\n",
    "\n",
    "    \"\"\"    \n",
    "       * If the DataLoader has no batches, it returns NaN (Not a Number) to clearly indicate that a loss calculation was impossible.\n",
    "       * This prevents division-by-zero errors later.\n",
    "        \n",
    "        Determine Number of Batches to Process:\n",
    "        * num_batches is None: If the caller doesn't specify a number of batches (num_batches=None),\n",
    "          the function will process the entire DataLoader. \n",
    "          This is used for a full evaluation.\n",
    "\n",
    "        * num_batches is provided: The function will process at most the requested number of batches. \n",
    "          The min function ensures we don't try to process more batches than the DataLoader actually contains.\n",
    "          This is useful for a quick, partial evaluation during training to save time.\n",
    "    \"\"\"\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    \n",
    "    \"\"\" The Core Loop: Process Batches and Accumulate Loss: \"\"\"\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Calculate and Return the Average:\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65c1717d-630e-4899-a077-9e57188d4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This function provides a snapshot of the model's performance on both the training and validation datasets \n",
    "      - At a specific point in time.\n",
    "    * \n",
    "    \n",
    "\"\"\"\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    \n",
    "    \"\"\"\n",
    "        * This command tells the model to change its behavior for evaluation.\n",
    "        * It disables layers like Dropout and Batch Normalization that behave differently during training and evaluation. \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    \"\"\"\n",
    "        * Disable Gradient Calculation.\n",
    "        * This creates a context manager that significantly boosts performance and reduces memory usage during evaluation.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        \"\"\"\n",
    "            * Calculate Losses\n",
    "            * This is the core of the function—calculating the actual performance metrics.\n",
    "            * calc_loss_loader: This function computes the average loss over several batches from a DataLoader.\n",
    "            * train_loader: The data the model is being trained on. The loss here shows how well the model has learned its lessons.\n",
    "            * val_loader: \n",
    "              - The held-out data the model has never seen during training.\n",
    "              - The loss here tests how well the model can apply its lessons to new, unseen problems (its ability to generalize).\n",
    "            * eval_iter: Instead of calculating the loss over the entire (potentially huge) dataset, \n",
    "              - this parameter limits the evaluation to a set number of batches. \n",
    "              - This makes evaluation much faster, providing a good estimate of performance without the computational cost.\n",
    "        \"\"\"\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "    \"\"\"\n",
    "        * Switch Back to Training Mode:\n",
    "        * This is a critical clean-up step. \n",
    "          - It reverts the model back to its training mode, re-enabling dropout and other training-specific behaviors.\n",
    "          - Forgetting to do this would break the next training step.   \n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    \"\"\"\n",
    "       * Return the Results:\n",
    "         - The function returns two numbers: the training loss and the validation loss.\n",
    "         - These two numbers together tell the most important story about your model's training progress.\n",
    "    \"\"\"\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bb47270-134d-4f5e-9001-ee6169fc237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can implement the text generation process, as shown in the following listing.\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    #Converts a text string to a tensor of token IDs.\n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)    # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    #Converts token IDs back to text.\n",
    "    flat = token_ids.squeeze(0)                # Remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bf4b9d9-b72c-489c-a743-a16f3aa8f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Generation Function\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "\n",
    "    # Loop for Token Generation\n",
    "    # Generates one token per iteration until max_new_tokens are created.\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop context if needed\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(idx_cond)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        # Focus on last time step\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # Get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Sample next token (greedy)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        \n",
    "        # Append to sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b05c559-826e-4451-82dc-05a90cc8135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This function takes a text prompt, uses the model to generate a continuation of that prompt, and prints the result.\n",
    "\"\"\"\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    \"\"\"\n",
    "        * Switch to Evaluation Mode:\n",
    "        * Prepares the model for inference, not training.\n",
    "        * Disables layers like Dropout to ensure deterministic and stable behavior. \n",
    "        * Same input to always produce the same output during text generation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    \"\"\"\n",
    "        * Determine the Model's Context Length.\n",
    "        * Finds out the maximum sequence length the model can handle.\n",
    "        * This is a smart way to get this parameter directly from the model itself.\n",
    "    \"\"\"\n",
    "    context_size = model.transformer.wpe.weight.shape[0]\n",
    "\n",
    "    \"\"\"\n",
    "        * Prepare the Input Prompt:\n",
    "        * text_to_token_ids: Converts the human-readable string start_context (e.g., \"Every effort moves you\")\n",
    "           into a sequence of token IDs using the model's tokenizer.\n",
    "        * .to(device): Ensures this tensor is on the same device as the model (e.g., GPU or CPU).\n",
    "    \"\"\"\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "\n",
    "    \"\"\"\n",
    "        * Generate Text (Without Affecting Gradients)\n",
    "        * This context manager is critical for performance. It tells PyTorch not to track operations for gradient calculation.\n",
    "        * Speeds up the generation process significantly and reduces memory usage, \n",
    "          as calculating gradients is unnecessary for just generating text.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "\n",
    "        \"\"\"\n",
    "            * generate_text_simple: This is the function that performs the actual autoregressive generation. \n",
    "            * It takes the initial encoded prompt and repeatedly predicts the next token, \n",
    "              appending it to the sequence until it has generated max_new_tokens=20 new tokens.\n",
    "        \"\"\"\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=20, context_size=context_size\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "        * Decode and Print the Result\n",
    "        * token_ids_to_text: Converts the sequence of token IDs back into a human-readable string.\n",
    "        * .replace('<|endoftext|>', ''): Removes the end-of-text token (<|endoftext|>) from the output if it appears, \n",
    "          making the printed result cleaner.\n",
    "    \"\"\"\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(f\"-> Generated: {decoded_text.replace('<|endoftext|>', '')}\")\n",
    "\n",
    "    \"\"\"\n",
    "        * Switch Back to Training Mode:\n",
    "        * It reverts the model back to training mode, re-enabling dropout and other training-specific behaviors. \n",
    "        * Forgetting this would mean the next training step would run in eval mode, which would break the training process.\n",
    "    \"\"\"\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9af768d-99a7-4ade-bf65-915b0186637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This function is the main training loop, the engine that drives the entire learning process. \n",
    "    * It orchestrates the interaction between the model, data, and optimizer to iteratively improve the model's performance.\n",
    "    * It processes data in batches, calculates the error, and updates the model's weights to minimize that error.\n",
    "    * It also includes crucial monitoring to track progress and diagnose issues.\n",
    "\"\"\"\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, \n",
    "                      num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    \"\"\"\n",
    "        * Initialize Tracking Lists.\n",
    "        * train_losses, val_losses: Empty lists to store the loss values over time.\n",
    "        * This data is used to plot learning curves and understand the training dynamics.\n",
    "    \"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "    tokens_seen = 0\n",
    "\n",
    "    \"\"\"\n",
    "        * global_step: A counter that increments with every batch processed. \n",
    "        * This is a more precise measure of progress than just epochs, especially for large datasets.\n",
    "    \"\"\"\n",
    "    global_step = 0\n",
    "\n",
    "    \"\"\"\n",
    "        * Epoch Loop\n",
    "        * An epoch is one full pass through the entire training dataset. The model will see all the training data num_epochs times.\n",
    "        \n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        \"\"\"\n",
    "            * Set Model to Training Mode\n",
    "            * Activates training-specific behaviors like Dropout and Batch Normalization.\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "\n",
    "        \"\"\"\n",
    "            * The Core Training Steps for Each Batch\n",
    "            * This inner loop iterates over every batch in the training DataLoader. \n",
    "            * This is where the actual learning happens.\n",
    "        \"\"\"\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            \"\"\"\n",
    "                * PyTorch accumulates gradients. This step sets all gradients to zero before calculating new ones for the current batch.\n",
    "                * Forgetting this would mix gradients from different batches, causing incorrect and unstable updates.\n",
    "            \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \"\"\"\n",
    "               * The model makes predictions on the batch (input_batch)\n",
    "               * calc_loss_batch calculates how wrong those predictions are compared to the target_batch.\n",
    "               * This single loss value is the measure of the model's error.\n",
    "            \"\"\"\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\n",
    "            \"\"\"\n",
    "                * Backward Pass (Calculate Gradients):\n",
    "                * The \"Learning\": This is backpropagation. \n",
    "                * It calculates the gradient of the loss with respect to every single parameter in the model. \n",
    "                * The gradients indicate the direction and amount each weight needs to be adjusted to reduce the error.\n",
    "            \"\"\"\n",
    "            loss.backward()\n",
    "\n",
    "            \"\"\"\n",
    "                * Update Weights:\n",
    "                * The \"Improvement\": The optimizer (e.g., AdamW) uses the calculated gradients to actually update the model's weights.\n",
    "                * This is the step that makes the model slightly better.\n",
    "            \"\"\"\n",
    "            optimizer.step()\n",
    "\n",
    "            \"\"\"\n",
    "                * Track Progress:\n",
    "                * Simply increments the step counter.\n",
    "            \"\"\"\n",
    "            global_step += 1\n",
    "\n",
    "            # track tokens seen\n",
    "            tokens_seen += targets.numel()\n",
    "            \n",
    "            \"\"\"\n",
    "                * Periodic Evaluation and logging\n",
    "                * if global_step % eval_freq == 0:\n",
    "                  - Every eval_freq batches (e.g., every 5 steps), it pauses training to evaluate the model\n",
    "                * evaluate_model: Calls the function to calculate the current loss on both training and validation sets.\n",
    "                  - This is the key to monitoring for overfitting.\n",
    "                * Prints the current losses to the console, providing real-time feedback.\n",
    "            \"\"\"            \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, \n",
    "                                                     device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} | Step {global_step:06d}\")\n",
    "                print(f\"Training loss: {train_loss:.4f} | Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "                \n",
    "        \"\"\"\n",
    "            * Generate Sample After Each Epoch:\n",
    "            * After finishing a full pass through the training data (one epoch), \n",
    "              it generates a text sample from a fixed prompt (start_context).\n",
    "            * This provides a qualitative check.\n",
    "            * You can visually see the text quality improving from gibberish to coherent sentences as training progresses,\n",
    "        \"\"\"\n",
    "        print(f\"\\nEpoch {epoch+1} completed:\")\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    \"\"\"\n",
    "        * Return Training History.\n",
    "        * Finally, the function returns the lists of recorded losses. \n",
    "        * These can be used to plot graphs and analyze the entire training run.\n",
    "    \"\"\"\n",
    "    return train_losses, val_losses, tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05c16be2-22b7-4dd9-ac1d-50f3136c6972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.480680513381958\n",
      "Validation loss: 3.509775257110596\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    * These codes are about checking how well the model is doing on your training and validation data before or during training.\n",
    "\"\"\"\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    ")\n",
    "\n",
    "print('Training loss:', train_loss)\n",
    "print('Validation loss:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b02cc058-f372-49fc-9bf3-463e9e4f6eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Step 000005\n",
      "Training loss: 1.4292 | Validation loss: 1.4080\n",
      "Epoch 1/1 | Step 000010\n",
      "Training loss: 1.0968 | Validation loss: 1.1662\n",
      "Epoch 1/1 | Step 000015\n",
      "Training loss: 1.0998 | Validation loss: 1.0914\n",
      "Epoch 1/1 | Step 000020\n",
      "Training loss: 1.0254 | Validation loss: 1.0323\n",
      "Epoch 1/1 | Step 000025\n",
      "Training loss: 0.9779 | Validation loss: 0.9900\n",
      "Epoch 1/1 | Step 000030\n",
      "Training loss: 1.0156 | Validation loss: 0.9586\n",
      "Epoch 1/1 | Step 000035\n",
      "Training loss: 0.9620 | Validation loss: 0.9379\n",
      "Epoch 1/1 | Step 000040\n",
      "Training loss: 0.7245 | Validation loss: 0.9171\n",
      "Epoch 1/1 | Step 000045\n",
      "Training loss: 0.8878 | Validation loss: 0.8946\n",
      "Epoch 1/1 | Step 000050\n",
      "Training loss: 0.8958 | Validation loss: 0.8778\n",
      "Epoch 1/1 | Step 000055\n",
      "Training loss: 0.8706 | Validation loss: 0.8934\n",
      "Epoch 1/1 | Step 000060\n",
      "Training loss: 0.7652 | Validation loss: 0.8888\n",
      "Epoch 1/1 | Step 000065\n",
      "Training loss: 0.7304 | Validation loss: 0.8785\n",
      "Epoch 1/1 | Step 000070\n",
      "Training loss: 0.7307 | Validation loss: 0.8749\n",
      "Epoch 1/1 | Step 000075\n",
      "Training loss: 0.7319 | Validation loss: 0.8646\n",
      "Epoch 1/1 | Step 000080\n",
      "Training loss: 0.6807 | Validation loss: 0.8576\n",
      "Epoch 1/1 | Step 000085\n",
      "Training loss: 0.7317 | Validation loss: 0.8433\n",
      "Epoch 1/1 | Step 000090\n",
      "Training loss: 0.6120 | Validation loss: 0.8335\n",
      "Epoch 1/1 | Step 000095\n",
      "Training loss: 0.6550 | Validation loss: 0.8263\n",
      "Epoch 1/1 | Step 000100\n",
      "Training loss: 0.6440 | Validation loss: 0.8191\n",
      "Epoch 1/1 | Step 000105\n",
      "Training loss: 0.7082 | Validation loss: 0.8183\n",
      "Epoch 1/1 | Step 000110\n",
      "Training loss: 0.6333 | Validation loss: 0.8146\n",
      "Epoch 1/1 | Step 000115\n",
      "Training loss: 0.6526 | Validation loss: 0.8214\n",
      "\n",
      "Epoch 1 completed:\n",
      "-> Generated: Below is an instruction that describes a task. \n",
      "# Instruction:\n",
      "Convert the following verb to its gerund form: 'write'\n",
      "# Input:\n",
      "write\n",
      "# Response:\n",
      "The gerund form of 'write' is\n",
      "--------------------------------------------------\n",
      "Training completed in 375.41 minutes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    * This is the training loop setup.\n",
    "    * This script sets the optimizer, trains the model for 2 epochs with evaluation checkpoints, \n",
    "      tracks both training & validation loss, and finally prints how long training took.\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()   # captures the current timestamp (in seconds).\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\"\"\"\n",
    "    * AdamW optimizer (a version of Adam that decouples weight decay).\n",
    "      - model.parameters() → the model’s trainable weights.\n",
    "      - lr=0.00005 → very small learning rate for stable fine-tuning.\n",
    "      - weight_decay=0.1 → regularization (helps prevent overfitting by penalizing large weights).\n",
    "\"\"\"\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.00005, weight_decay=0.1\n",
    ")\n",
    "\n",
    "\n",
    "num_epochs = 1  # Train for 1 passes over the dataset. For larger models, we often use small epochs because training is expensive.\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,               # the LLM you’re fine-tuning.\n",
    "    train_loader,        # Train data batches.\n",
    "    val_loader,          # Validation data batches.\n",
    "    optimizer,           # AdamW defined above.\n",
    "    device,              # cpu or cuda.\n",
    "    num_epochs=num_epochs,    # total epochs to run.\n",
    "    eval_freq=5,         # evaluate every 5 training steps.\n",
    "    eval_iter=5,         # use 5 batches for evaluation each time.\n",
    "    start_context=format_input(val_data[0]), # example input string for generating text samples during training\n",
    "    tokenizer=tokenizer  # used for decoding outputs back into text.\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "    * It returns: \n",
    "       - train_losses → list of training losses over time.\n",
    "       - val_losses → list of validation losses.\n",
    "       - tokens_seen → number of tokens processed during training (useful for scaling laws).\n",
    "\"\"\"\n",
    "\n",
    "end_time = time.time()   # Captures the end time.\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f'Training completed in {execution_time_minutes:.2f} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c16d47c-a4cb-4cb2-bd15-f13b9c207e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Generated: Below is an instruction that describes a task. \n",
      "# Instruction:\n",
      "What is the formula for the area of a trapezoid?\n",
      "# Response:\n",
      "The formula for the area of a trapezoid is 2πr²\n"
     ]
    }
   ],
   "source": [
    "start_context=format_input(val_data[3])\n",
    "generate_and_print_sample(model, tokenizer, device, start_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b35bee72-7830-413e-a0e9-bff4ef3c606c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(train_losses)), train_losses, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(range(len(val_losses)), val_losses, label=\"Validation Loss\", marker=\"s\")\n",
    "\n",
    "plt.xlabel(\"Evaluation Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d5a65a5-0ca7-4808-8ca5-b8f57ac01947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    * This script is a safety check to ensure Ollama is running before your program tries to interact with it.\n",
    "    * Imports the psutil library, which allows you to inspect and monitor system processes, CPU, memory, etc.\n",
    "\"\"\"\n",
    "\n",
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):  # checks if a process is running on your system.\n",
    "    running = False\n",
    "    # iterates over all active processes but only fetches their name attribute (faster than fetching full info).\n",
    "    for proc in psutil.process_iter(['name']):\n",
    "        # checks if the given process_name string is inside the process name.\n",
    "        if process_name in proc.info['name']:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running('ollama')\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\n",
    "        'Ollama not running. Launch ollama before proceeding.'\n",
    ")\n",
    "print('Ollama running:', check_if_running('ollama'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85598be4-a059-4fcf-99fc-eaca4991974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This function is a low-level client for Ollama’s REST API.\n",
    "        - Builds a JSON payload with model + prompt + options.\n",
    "        - Sends it to http://localhost:11434/api/chat.\n",
    "        - Reads Ollama’s streaming JSON response line by line.\n",
    "        - Concatenates the generated text into a single string.\n",
    "        - Returns that text to the caller.\n",
    "        \n",
    "    * Imports Python’s built-in library for making HTTP requests (no external requests library needed).\n",
    "\"\"\"\n",
    "\n",
    "def query_model(\n",
    "    prompt, \n",
    "    model='llama3', \n",
    "    url='http://localhost:11434/api/chat'\n",
    "):\n",
    "    data = {          \n",
    "        'model': model,   # tells Ollama which LLM to use (e.g., llama3).\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': prompt} # in chat format.\n",
    "        ],\n",
    "        'options': {          # extra settings for generation\n",
    "            'seed': 123,      # makes output deterministic (same input → same result).\n",
    "            'temperature': 0, # makes model responses more focused/less random.\n",
    "            'num_ctx': 2048   # maximum number of tokens in context (window size).\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Converts the Python dictionary data → JSON string → UTF-8 encoded bytes.\n",
    "    payload = json.dumps(data).encode('utf-8')   \n",
    "\n",
    "    # Creates an HTTP POST request to the Ollama server.\n",
    "    request = urllib.request.Request( \n",
    "        url,                    # Ollama server\n",
    "        data=payload,           # Attaches the payload (JSON body).\n",
    "        method='POST'           # reates an HTTP POST request to the Ollama server.\n",
    "    )\n",
    "    request.add_header('Content-Type', 'application/json')   \n",
    "\n",
    "    # Send request + handle response\n",
    "    response_data = ''\n",
    "    with urllib.request.urlopen(request) as response:   # actually calls the Ollama API.\n",
    "        while True:\n",
    "            line = response.readline().decode('utf-8')  # convert from bytes to string.\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)                      # parse JSON chunk.\n",
    "            response_data += response_json['message']['content']  # Concatenates all chunks into response_data.\n",
    "\n",
    "    # returns the full generated model output.\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f2056-9dab-4160-98b7-83de0c26c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * You’re choosing which model Ollama should use for inference.\n",
    "\"\"\"\n",
    "\n",
    "model = 'llama3' # is the identifier of the model installed in your Ollama server\n",
    "result = query_model('What do Llamas eat?', model) # It sends your prompt/question (\"What do Llamas eat?\") to the Ollama REST API.\n",
    "print(result) # Prints the model’s answer in your Python console."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
