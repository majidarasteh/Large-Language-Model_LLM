# Fine Tuning for Classification
In this chapter, we transition from building and pretraining a general-purpose language model to specializing it for a concrete real-world task: **text classification**. We focus on fine-tuning a pretrained LLM to distinguish between “spam” and “not spam” messages—a classic binary classification problem. You will learn the key differences between instruction fine-tuning, which enables models to perform diverse tasks based on natural language prompts, and classification fine-tuning, which tailors a model to predict specific, predefined labels. Through hands-on examples, we cover the entire process: preparing a labeled dataset, modifying the model’s architecture, implementing the training loop, evaluating performance, and deploying the fine-tuned classifier. By the end of this chapter, you will have the skills to adapt LLMs for specialized classification tasks across various domains.

## Two Primary Fine-Tuning Paradigms
1. **Instruction Fine-Tuning**: Creates a generalist model that follows instructions. For example, the model can be asked "Is this spam?" or "Translate this to German." This flexibility is the key takeaway.
2. **Classification Fine-Tuning**: Creates a specialist model that maps inputs to a fixed set of predefined labels (spam/ham). Its strength is its narrow focus and simplicity for the task at hand.

The concept of a **specialist vs. a generalist** is a powerful and intuitive way to frame the difference. It helps readers understand the trade-off:
1. **Specialist (Classification-Tuned)**: Easier and cheaper to build, highly accurate at its specific job, but inflexible. It's a master of one trade.
2. **Generalist (Instruction-Tuned)**: More complex and expensive to build, versatile across many tasks, but might not be the absolute best at any single one compared to a specialist. It's a jack-of-all-trades.

The following figure illustrates two distinct scenarios for instruction fine-tuning and classification fine-tuning. This contrast demonstrates the core strength of instruction fine-tuning: it produces a generalist model capable of understanding and executing a wide range of tasks expressed through natural language prompts, rather than being limited to a single predefined function like a spam classifier.

<img width="911" height="405" alt="image" src="https://github.com/user-attachments/assets/11b0770f-6420-426e-a41d-30b816a8b536" />

### How this Sets Up the Rest of the Chapter

The chapter will now logically progress through the steps of creating a specialist model:
1. **Data Preparation**: How to get and prepare a dataset of spam/ham messages.
2. **Model Modification**: How to surgically alter the general-purpose GPT architecture (changing the output layer) to make it a specialist classifier.
3. **The Fine-Tuning Process**: How to train this modified model on the new data.
4. **Evaluation**: How to measure the performance of our new specialist.
5. **Usage**: How to use the finished model to classify new messages.

## Data Preparation

The first step in our classification task is to prepare the dataset:

* **Dataset**: We begin by downloading a real-world collection of SMS messages labeled as "spam" or "ham" (non-spam).
* **Imbalance Handling**: A common challenge in machine learning is dealing with imbalanced data, and this dataset is no exception, containing significantly more "ham" messages than "spam."
* **Balancing**: To ensure our model learns to identify both classes effectively and isn't biased toward the majority class, we rectify this imbalance by **undersampling** the "ham" instances to create a balanced dataset with an equal number of spam and non-spam examples.
* **Train/Validation/Test Split**: Finally, we split this refined dataset into standard **training (70%), validation (10%), and test (20%)** sets. This partitioning allows us to train the model, tune its parameters, and ultimately evaluate its performance on completely unseen data, providing a robust foundation for the fine-tuning process.

### Creating data loaders
To efficiently feed the text data into the model during training, we create PyTorch DataLoaders. Since messages have different lengths, we must standardize them for batching. Here the core problem is the variable-length input:
1. **Past Approach**: Previously, text was split into uniform chunks (e.g., using a sliding window), so every input was the same size, making them easy to batch together.
2. **New Challenge**: Individual text messages (like SMS) are all different lengths. A neural network requires inputs within a batch to be the same dimensions.

To solve the variable-length problem, the text must be standardized. The two common methods are:

1. **Truncation**: Chopping off the end of longer messages to make all messages as short as the shortest one.
   * **Pro**: Fast and uses less memory.
   * **Con**: You lose information! If the important part of a message is at the end, it gets thrown away, which can hurt the model's performance.
     
2. **Padding**: Adding a special, meaningless padding token to the end of shorter messages to make them all as long as the longest message.
   * **Pro**: Preserves all the original information in every message.
   * **Con**: Uses more memory and computation because the model has to process all those extra padding tokens.

We chose padding to avoid losing any important information from the messages. The technical implementation is as follow:
1. The model doesn't understand words; it understands numbers (token IDs).
2. Therefore, we don't pad with the word ```<|endoftext|>```. Instead, we pad with its corresponding **token ID: 50256**.
3. This is done after the text has been converted into a list of numbers (tokenized). So, a short message like ```["Hi", "there"]``` (IDs ```[123, 456]```) might become ```[123, 456, 50256, 50256, 50256]``` to match the length of a longer message.

This process is about making all text messages the same length by adding a special **"dummy" number (50256)** to the end of shorter messages. This allows the computer to efficiently process many messages at once in a batch without losing any of the original text content. For example the following figure shows padding:

<img width="911" height="459" alt="image" src="https://github.com/user-attachments/assets/370d2a6c-d16b-46ff-aca5-2473e92f8fd1" />


In the text classification, there is a fundamental shift in the model's objective and its original design. There is a shift from next token prediction to classification.  

* **Original Purpose (Pretraining):** The model was trained to predict the next token in a sequence.
* **New Purpose (Fine-tuning for Classification):** he model is now trained to predict a single, overall class label for an entire input sequence.

In the text classification, as an example, the structure of the data that will be fed into the model during training could be as follow:

* **input_batch**: A tensor with dimensions [8, 120].
  - **8** is the batch size (8 independent text messages processed together).
  - **120** is the sequence length. Each message has been padded/truncated to be exactly 120 tokens long. This is the uniform length required for batching.
    
* **target_batch**: A tensor with dimensions [8].
  - This is not a sequence. It's a simple list of 8 numbers.
  - Each number is the correct class label (0 or 1) for the corresponding message in the input_batch.

<img width="640" height="585" alt="image" src="https://github.com/user-attachments/assets/1d157efc-d277-4a6e-961b-ede0e9f1849d" />

### Loading a Pre-Trained Base Model 
This section describes the crucial step of loading a pre-trained base model before adapting it for a new task. The objective is not to train a model from scratch but to leverage the general language understanding a model has already gained during its pre-training on a massive text corpus. This is more efficient and effective than training a classifier on spam messages from scratch. The process of loading and verification is as follow:

1. **Initialize with Pre-trained Weights**: First we load the parameters (weights) from a pre-existing model (like GPT-2) into a built GPT model architecture. This gives you a model that is already a powerful text generator and language understander.
2. **Sanity Check**: It's crucial to verify that the weights were loaded correctly. The text does this by using a text generation utility on a simple prompt. If the model produces coherent, sensible text (e.g., completing "Every effort moves you" with "forward."), it confirms the model is functioning as a proper language model.
3. **Test Zero-Shot Ability (Baseline)**: Before any fine-tuning, the text checks if the model can already perform the desired task ("Is this spam?") just based on its pre-training. This is called zero-shot performance.
   * **The Result:** The model fails. It doesn't answer the question; it just continues generating text in the same style. For example, given the prompt "Is the following text 'spam'? ...", it might just repeat the question or continue the sentence instead of answering "yes" or "no". This "failure" is a critical teaching point. It demonstrates a key concept:
     - A model that is only pre-trained (on a next-word prediction task) is a **general-purpose text completer**. It has no inherent ability to follow instructions or perform specific classification tasks unless it is specifically trained to do so.
     - This failed test establishes the baseline and provides the motivation for the next step: **we must modify and fine-tune** this general model to make it a specialized spam classifier.

In summary, this section is about taking a powerful, pre-trained generator and confirming that, in its current state, it is useless for our specific task. This sets the stage for the necessary architectural changes and training process (fine-tuning) to turn this generalist into a specialist.


### Architectural Modification 
This section describes the key architectural modification required to turn a generative language model into a classifier. The core modification is swapping the output layer (the "head") to change its purpose.
1. **Original Head (for Generation):**
   * **Function**: Predicts the next word in a sequence.
   * **Architecture**: A linear layer that maps the model's internal representation (e.g., 768-dimensional vectors) to a score for every possible token in its massive vocabulary (50,257 options).
   * **Output**: A vector of size 50,257.
     
2. **New Classification Head (for Spam Detection):**
   * **Function**: Predicts a single class label for the entire input sequence.
   * **Architecture**: A new linear layer that maps the same internal representation (768-dimension) to a score for each of the two possible classes ("spam" and "not spam").
   * **Output**: A vector of size 2.

**Why Two Output Nodes? (The Important Detail)** even for a binary (yes/no) task, we use two output nodes instead of one.  

1. **Technical Reason (The "How"):** Using two nodes allows them to use the standard cross-entropy loss function directly, which is the default for classification tasks in frameworks like PyTorch. This loss function is designed to compare a distribution over multiple classes (from the model) against a true label.
2. **Practical Reason (The "Why"):** This approach is more generalizable. The same code and model architecture can be instantly reused for a classification task with 3, 10, or 100 classes just by changing the number of output nodes. Using a single output node would require a different loss function (like Binary Cross-Entropy) and changes to the training code.

**The Resulting Data Flow**:  After this change, for a given input text, the model no longer produces a list of next-token probabilities. Instead, it produces two numbers (logits):
* One score for class 0 ("not spam")
* One score for class 1 ("spam")

The class with the higher score is the model's prediction. As the following figure, this simple swap is the primary architectural step needed to repurpose a powerful generative model for a specific discriminative task.

<img width="599" height="760" alt="image" src="https://github.com/user-attachments/assets/53c2192a-2b20-4386-b737-3bc68b1aa33b" />

