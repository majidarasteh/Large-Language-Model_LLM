{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173e3c83-5faa-4ab3-9a76-a33670eea163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import urllib.request\n",
    "import math\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from implemented_modules import GPTModel\n",
    "from implemented_modules import generate_text_simple\n",
    "from implemented_modules import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51c9867-473b-4a6a-a73b-c6775e82219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can implement the text generation process, as shown in the following listing.\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    #Converts a text string to a tensor of token IDs.\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)    # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    #Converts token IDs back to text.\n",
    "    flat = token_ids.squeeze(0)                # Remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478ee4e4-33d6-46de-a9fd-4c2f4d9d8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * Calculates loss for a single batch.\n",
    "    * This function is the \"engine\" of learning. \n",
    "    * The optimizer will use this loss value to adjust every single weight in the model.\n",
    "\"\"\"\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "\n",
    "    \"\"\"\n",
    "        * Move Data to the Correct Device:\n",
    "          - This ensures the data is on the same hardware as the model (e.g., both on the GPU or both on the CPU).\n",
    "          - This is necessary for the upcoming computations.\n",
    "          \n",
    "        * input_batch: The token IDs for the input sequence (e.g., [\"Every\", \"effort\", \"moves\"]).\n",
    "        * target_batch: The token IDs for the target sequence, which is the input shifted by one (e.g., [\"effort\", \"moves\", \"you\"]). \n",
    "          - These are the \"correct answers.\"\n",
    "    \"\"\"\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    \"\"\"\n",
    "        * Forward Pass: Get Model Predictions:\n",
    "          - The model processes the input_batch and produces its predictions.\n",
    "          - logits: The model's raw, unnormalized output. Its shape is [batch_size, num_tokens, vocab_size].\n",
    "          - Example: \n",
    "              - For a batch of 2 sequences, each with 3 tokens, and a vocabulary of 50,257 words, the shape is [2, 3, 50257].\n",
    "        * For each of the 6 token positions (2 sequences * 3 tokens), the model outputs 50,257 scores.\n",
    "          - One for each possible next word in the vocabulary.\n",
    "    \"\"\"\n",
    "    logits = model(input_batch)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "        * Calculate the Loss (The Most Important Step)\n",
    "        * Flatten the tensors for cross-entropy calculation\n",
    "          - logits.flatten(0, 1): This reshapes the logits from [2, 3, 50257] to [6, 50257]. \n",
    "             - It combines the batch and sequence dimensions.\n",
    "             \n",
    "          - target_batch.flatten(): This reshapes the targets from [2, 3] to [6].\n",
    "             - It creates a simple list of the 6 correct answer token IDs.\n",
    "    \"\"\"\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7003555-43cf-4a52-82c5-550e3246eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This function calculates the average loss of a model over one or more batches of data from a DataLoader.\n",
    "\"\"\"\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"Calculates average loss over multiple batches.\"\"\"\n",
    "    total_loss = 0.\n",
    "\n",
    "    \"\"\"    \n",
    "       * If the DataLoader has no batches, it returns NaN (Not a Number) to clearly indicate that a loss calculation was impossible.\n",
    "       * This prevents division-by-zero errors later.\n",
    "        \n",
    "        Determine Number of Batches to Process:\n",
    "        * num_batches is None: If the caller doesn't specify a number of batches (num_batches=None),\n",
    "          the function will process the entire DataLoader. \n",
    "          This is used for a full evaluation.\n",
    "\n",
    "        * num_batches is provided: The function will process at most the requested number of batches. \n",
    "          The min function ensures we don't try to process more batches than the DataLoader actually contains.\n",
    "          This is useful for a quick, partial evaluation during training to save time.\n",
    "    \"\"\"\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    \n",
    "    \"\"\" The Core Loop: Process Batches and Accumulate Loss: \"\"\"\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Calculate and Return the Average:\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dff411-e6b1-4f4d-a8ad-85033c7bd14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This function provides a snapshot of the model's performance on both the training and validation datasets \n",
    "      - At a specific point in time.\n",
    "    * \n",
    "    \n",
    "\"\"\"\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    \n",
    "    \"\"\"\n",
    "        * This command tells the model to change its behavior for evaluation.\n",
    "        * It disables layers like Dropout and Batch Normalization that behave differently during training and evaluation. \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    \"\"\"\n",
    "        * Disable Gradient Calculation.\n",
    "        * This creates a context manager that significantly boosts performance and reduces memory usage during evaluation.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        \"\"\"\n",
    "            * Calculate Losses\n",
    "            * This is the core of the functionâ€”calculating the actual performance metrics.\n",
    "            * calc_loss_loader: This function computes the average loss over several batches from a DataLoader.\n",
    "            * train_loader: The data the model is being trained on. The loss here shows how well the model has learned its lessons.\n",
    "            * val_loader: \n",
    "              - The held-out data the model has never seen during training.\n",
    "              - The loss here tests how well the model can apply its lessons to new, unseen problems (its ability to generalize).\n",
    "            * eval_iter: Instead of calculating the loss over the entire (potentially huge) dataset, \n",
    "              - this parameter limits the evaluation to a set number of batches. \n",
    "              - This makes evaluation much faster, providing a good estimate of performance without the computational cost.\n",
    "        \"\"\"\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "    \"\"\"\n",
    "        * Switch Back to Training Mode:\n",
    "        * This is a critical clean-up step. \n",
    "          - It reverts the model back to its training mode, re-enabling dropout and other training-specific behaviors.\n",
    "          - Forgetting to do this would break the next training step.   \n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    \"\"\"\n",
    "       * Return the Results:\n",
    "         - The function returns two numbers: the training loss and the validation loss.\n",
    "         - These two numbers together tell the most important story about your model's training progress.\n",
    "    \"\"\"\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3a4210-7828-4554-b954-53e6eec07459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This function takes a text prompt, uses the model to generate a continuation of that prompt, and prints the result.\n",
    "\"\"\"\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    \"\"\"\n",
    "        * Switch to Evaluation Mode:\n",
    "        * Prepares the model for inference, not training.\n",
    "        * Disables layers like Dropout to ensure deterministic and stable behavior. \n",
    "        * Same input to always produce the same output during text generation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    \"\"\"\n",
    "        * Determine the Model's Context Length.\n",
    "        * Finds out the maximum sequence length the model can handle.\n",
    "        * This is a smart way to get this parameter directly from the model itself.\n",
    "        * model.pos_emb: has one embedding vector for each possible position in the input sequence.\n",
    "        * .shape[0]: therefore defines the model's context_length (e.g., 256, 1024).\n",
    "    \"\"\"\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    \"\"\"\n",
    "        * Prepare the Input Prompt:\n",
    "        * text_to_token_ids: Converts the human-readable string start_context (e.g., \"Every effort moves you\")\n",
    "           into a sequence of token IDs using the model's tokenizer.\n",
    "        * .to(device): Ensures this tensor is on the same device as the model (e.g., GPU or CPU).\n",
    "    \"\"\"\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "\n",
    "    \"\"\"\n",
    "        * Generate Text (Without Affecting Gradients)\n",
    "        * This context manager is critical for performance. It tells PyTorch not to track operations for gradient calculation.\n",
    "        * Speeds up the generation process significantly and reduces memory usage, \n",
    "          as calculating gradients is unnecessary for just generating text.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "\n",
    "        \"\"\"\n",
    "            * generate_text_simple: This is the function that performs the actual autoregressive generation. \n",
    "            * It takes the initial encoded prompt and repeatedly predicts the next token, \n",
    "              appending it to the sequence until it has generated max_new_tokens=20 new tokens.\n",
    "        \"\"\"\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=20, context_size=context_size\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "        * Decode and Print the Result\n",
    "        * token_ids_to_text: Converts the sequence of token IDs back into a human-readable string.\n",
    "        * .replace('<|endoftext|>', ''): Removes the end-of-text token (<|endoftext|>) from the output if it appears, \n",
    "          making the printed result cleaner.\n",
    "    \"\"\"\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(f\"-> Generated: {decoded_text.replace('<|endoftext|>', '')}\")\n",
    "\n",
    "    \"\"\"\n",
    "        * Switch Back to Training Mode:\n",
    "        * It reverts the model back to training mode, re-enabling dropout and other training-specific behaviors. \n",
    "        * Forgetting this would mean the next training step would run in eval mode, which would break the training process.\n",
    "    \"\"\"\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5900cdbb-ad06-4c05-97e6-ac98fc4aec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This function is the main training loop, the engine that drives the entire learning process. \n",
    "    * It orchestrates the interaction between the model, data, and optimizer to iteratively improve the model's performance.\n",
    "    * It processes data in batches, calculates the error, and updates the model's weights to minimize that error.\n",
    "    * It also includes crucial monitoring to track progress and diagnose issues.\n",
    "\"\"\"\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, \n",
    "                      num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    \"\"\"\n",
    "        * Initialize Tracking Lists.\n",
    "        * train_losses, val_losses: Empty lists to store the loss values over time.\n",
    "        * This data is used to plot learning curves and understand the training dynamics.\n",
    "    \"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    \"\"\"\n",
    "        * global_step: A counter that increments with every batch processed. \n",
    "        * This is a more precise measure of progress than just epochs, especially for large datasets.\n",
    "    \"\"\"\n",
    "    global_step = 0\n",
    "\n",
    "    \"\"\"\n",
    "        * Epoch Loop\n",
    "        * An epoch is one full pass through the entire training dataset. The model will see all the training data num_epochs times.\n",
    "        \n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        \"\"\"\n",
    "            * Set Model to Training Mode\n",
    "            * Activates training-specific behaviors like Dropout and Batch Normalization.\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "\n",
    "        \"\"\"\n",
    "            * The Core Training Steps for Each Batch\n",
    "            * This inner loop iterates over every batch in the training DataLoader. \n",
    "            * This is where the actual learning happens.\n",
    "        \"\"\"\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            \"\"\"\n",
    "                * PyTorch accumulates gradients. This step sets all gradients to zero before calculating new ones for the current batch.\n",
    "                * Forgetting this would mix gradients from different batches, causing incorrect and unstable updates.\n",
    "            \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \"\"\"\n",
    "               * The model makes predictions on the batch (input_batch)\n",
    "               * calc_loss_batch calculates how wrong those predictions are compared to the target_batch.\n",
    "               * This single loss value is the measure of the model's error.\n",
    "            \"\"\"\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\n",
    "            \"\"\"\n",
    "                * Backward Pass (Calculate Gradients):\n",
    "                * The \"Learning\": This is backpropagation. \n",
    "                * It calculates the gradient of the loss with respect to every single parameter in the model. \n",
    "                * The gradients indicate the direction and amount each weight needs to be adjusted to reduce the error.\n",
    "            \"\"\"\n",
    "            loss.backward()\n",
    "\n",
    "            \"\"\"\n",
    "                * Update Weights:\n",
    "                * The \"Improvement\": The optimizer (e.g., AdamW) uses the calculated gradients to actually update the model's weights.\n",
    "                * This is the step that makes the model slightly better.\n",
    "            \"\"\"\n",
    "            optimizer.step()\n",
    "\n",
    "            \"\"\"\n",
    "                * Track Progress:\n",
    "                * Simply increments the step counter.\n",
    "            \"\"\"\n",
    "            global_step += 1\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "                * Periodic Evaluation and logging\n",
    "                * if global_step % eval_freq == 0:\n",
    "                  - Every eval_freq batches (e.g., every 5 steps), it pauses training to evaluate the model\n",
    "                * evaluate_model: Calls the function to calculate the current loss on both training and validation sets.\n",
    "                  - This is the key to monitoring for overfitting.\n",
    "                * Prints the current losses to the console, providing real-time feedback.\n",
    "            \"\"\"\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, \n",
    "                                                     device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} | Step {global_step:06d}\")\n",
    "                print(f\"Training loss: {train_loss:.4f} | Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "                \n",
    "        \"\"\"\n",
    "            * Generate Sample After Each Epoch:\n",
    "            * After finishing a full pass through the training data (one epoch), \n",
    "              it generates a text sample from a fixed prompt (start_context).\n",
    "            * This provides a qualitative check.\n",
    "            * You can visually see the text quality improving from gibberish to coherent sentences as training progresses,\n",
    "        \"\"\"\n",
    "        print(f\"\\nEpoch {epoch+1} completed:\")\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    \"\"\"\n",
    "        * Return Training History.\n",
    "        * Finally, the function returns the lists of recorded losses. \n",
    "        * These can be used to plot graphs and analyze the entire training run.\n",
    "    \"\"\"\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ff8d5b-4f75-4fc7-9e2e-d6dae71fc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This code defines the architectural blueprint for a specific version of a GPT-like model.\n",
    "    * GPT_CONFIG_124M dictionary is a centralized set of instructions that defines the exact structure and behavior of a neural network\n",
    "    * It's a common and best practice to store all model hyperparameters in a single, easily modifiable configuration object.\n",
    "    * The \"124M\" in the variable name refers to the total number of parameters\n",
    "    \n",
    "      - \"vocab_size\": 50257: The size of the model's vocabulary.\n",
    "      - \"context_length\": 256: The maximum length of a sequence the model can process.\n",
    "      - \"emb_dim\": 768: The dimensionality of the embedding vectors.\n",
    "      - \"n_heads\": 12: The number of attention heads in the multi-head attention mechanism.\n",
    "      - \"n_layers\": 12: The number of transformer blocks stacked on top of each other.\n",
    "      - \"drop_rate\": 0.1: The dropout rate.\n",
    "      - \"qkv_bias\": False: A flag indicating whether to use bias terms in the Query, Key, and Value linear projections \n",
    "         within the attention mechanism.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,  # Reduced for faster training\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed01e6e-ccb9-44f5-a701-f15e554bcd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    " # Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f35a0f80-a785-4854-bd9b-83b699261096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file\n",
    "if not os.path.exists(\"Resources/Story.txt\"):\n",
    "    URL = (\"https://raw.githubusercontent.com/majidarasteh/Large-Language-Model_LLM/refs/heads/main/Resources/Story.txt\")\n",
    "    file_path = \"Story.txt\"\n",
    "    urllib.request.urlretrieve(URL, file_path)\n",
    "\n",
    "with open(\"Story.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    story_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0979271d-9b84-4dfd-b272-329bf02ab8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 34473\n",
      "Tokens: 8581\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    * Check the uploaded file with the tokenizer.\n",
    "\"\"\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_characters = len(story_text)\n",
    "total_tokens = len(tokenizer.encode(story_text))\n",
    "print('Characters:', total_characters)\n",
    "print('Tokens:', total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1247c0bf-d3e3-4a6e-84b7-234d451056c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (90% train, 10% validation)\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(story_text))\n",
    "train_data = story_text[:split_idx]\n",
    "val_data = story_text[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6d43c33-a7b7-4c26-80a3-6be771d740ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93fe0310-752a-499f-8b79-26f77b319f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([1, 256]) torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "print('Train loader:')\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print('\\nValidation loader:')\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bcb5823-df90-4ea9-9a90-1c8a11285256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Training on 15 batches per epoch\n",
      "Context length: 256\n",
      "Vocabulary size: 50257\n",
      "--------------------------------------------------\n",
      "Epoch 1/3 | Step 000005\n",
      "Training loss: 8.2260 | Validation loss: 7.9530\n",
      "Epoch 1/3 | Step 000010\n",
      "Training loss: 6.7631 | Validation loss: 6.5416\n",
      "Epoch 1/3 | Step 000015\n",
      "Training loss: 6.1900 | Validation loss: 5.9985\n",
      "\n",
      "Epoch 1 completed:\n",
      "-> Generated: Every effort moves you the the the the the the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 2/3 | Step 000020\n",
      "Training loss: 5.6746 | Validation loss: 5.8071\n",
      "Epoch 2/3 | Step 000025\n",
      "Training loss: 5.0340 | Validation loss: 5.7211\n",
      "Epoch 2/3 | Step 000030\n",
      "Training loss: 4.8122 | Validation loss: 5.7417\n",
      "\n",
      "Epoch 2 completed:\n",
      "-> Generated: Every effort moves youâ€™sâ€™s, Iâ€™s toâ€™s Iâ€™s to\n",
      "--------------------------------------------------\n",
      "Epoch 3/3 | Step 000035\n",
      "Training loss: 5.1534 | Validation loss: 5.8917\n",
      "Epoch 3/3 | Step 000040\n",
      "Training loss: 4.8555 | Validation loss: 5.6629\n",
      "Epoch 3/3 | Step 000045\n",
      "Training loss: 4.6537 | Validation loss: 5.6922\n",
      "\n",
      "Epoch 3 completed:\n",
      "-> Generated: Every effort moves you know, Iâ€™m Iâ€™s really to Iâ€™m Iâ€™m\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    * This code is the final setup and execution command that puts all the previously defined components together.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    * torch.manual_seed(123): Sets the random number generator to a specific starting point (seed).\n",
    "    * This ensures that the model's initial random weights are the same every time you run the code.\n",
    "    * It is crucial for reproducibility (getting the same results from the same code).\n",
    "\"\"\"\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    * model = GPTModel(GPT_CONFIG_124M)\n",
    "    * It creates an instance of your GPTModel class, using the configuration defined in the GPT_CONFIG_124M dictionary. \n",
    "    * At this point, the model's weights are random.\n",
    "\"\"\"\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    * model.to(device): Moves the entire model to the specified computing device (e.g., a GPU if device='cuda'). \n",
    "    * This is essential for performance; all model calculations and the data it processes must be on the same device.\n",
    "\"\"\"\n",
    "model.to(device);\n",
    "\n",
    "\"\"\"\n",
    "    * Initialize optimizer\n",
    "    * Purpose: Creates the algorithm that will update the model's weights during training.\n",
    "    * AdamW: A modern, highly effective optimizer that is the standard choice for training LLMs. It's an enhanced version of Adam.\n",
    "    * lr=0.0004:The learning rate. \n",
    "        - This is a hyperparameter that controls how big of a \"step\" the optimizer takes when updating weights.\n",
    "    * weight_decay=0.1: A regularization technique that helps prevent overfitting.\n",
    "        - by penalizing large weights, encouraging the model to find simpler solutions.\n",
    "\"\"\"\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "  \n",
    "\"\"\"\n",
    "    * Initialize the Tokenizer\n",
    "    * Prepares the tokenizer that will be used to convert the start_context string into token IDs for the text generation samples.\n",
    "\"\"\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "\"\"\"\n",
    "    * Set Training Hyperparameters:\n",
    "     - num_epochs = 5: The model will make 5 complete passes through the entire training dataset.\n",
    "     - eval_freq = 5: Evaluation will be performed every 5 training steps (i.e., every 5 batches processed).\n",
    "     - eval_iter = 2: During each evaluation, only 2 batches from the training and validation sets will be used to calculate the loss.\n",
    "     - start_context = \"Every effort moves you\": This is the fixed prompt that will be used to generate text samples after each epoch.\n",
    "         - allowing you to visually track the model's improving language skills.\n",
    "\"\"\"\n",
    "num_epochs = 3\n",
    "eval_freq = 5  # Evaluate every 5 steps\n",
    "eval_iter = 2  # Use 2 batches for evaluation\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    * This prints a summary of the training setup, which is useful for logging and debugging. \n",
    "\"\"\"\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training on {len(train_loader)} batches per epoch\")\n",
    "print(f\"Context length: {GPT_CONFIG_124M['context_length']}\")\n",
    "print(f\"Vocabulary size: {GPT_CONFIG_124M['vocab_size']}\")\n",
    "print(\"-\" * 50)\n",
    "    \n",
    "\"\"\"\n",
    "    * Start the Training Loop:\n",
    "    * The function returns the history of training and validation losses.\n",
    "        -  You could later use to plot a graph of the training progress.\n",
    "\"\"\"\n",
    "train_losses, val_losses = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq, eval_iter, start_context, tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0132c2f4-081c-4b53-a2a6-85bf1b600632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig('training_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05ac98f1-2c87-41d1-916f-f97c9fd7520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This is an enhanced text generation function that incorporates temperature scaling and top-k sampling \n",
    "      - to control the randomness and quality of the generated text. \n",
    "    * generate function: generates new text one token at a time, but with two advanced techniques to avoid repetitive and boring outputs\n",
    "        - Temperature Scaling: Controls the \"creativity\" vs. \"safety\" of the model's choices.\n",
    "        - Top-K Sampling: Restricts the model's choices to only the K most likely next tokens.\n",
    "            - For preventing it from choosing nonsensical words.\n",
    "\"\"\"\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    \"\"\"\n",
    "        * Loop for Token Generation.\n",
    "        * The loop runs for max_new_tokens iterations, generating one token per step.\n",
    "    \"\"\"\n",
    "    for _ in range(max_new_tokens):\n",
    "        \"\"\"\n",
    "            * idx_cond crops the current sequence to the model's maximum context_size.\n",
    "            * This is necessary because the model can't process infinitely long sequences.\n",
    "        \"\"\"\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        \"\"\"\n",
    "            * Get Model Predictions:\n",
    "             - with torch.no_grad(): Disables gradient calculation for a massive speed boost during inference.\n",
    "             - model(idx_cond): Gets the raw output (logits) for the entire sequence.\n",
    "             - logits = logits[:, -1, :]: We only care about the logits for the very last token position, \n",
    "               as this is what we use to predict the next token.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "            * Apply Top-K Filtering (if enabled): This block ensures the model only chooses from the top_k most likely tokens.\n",
    "             - torch.topk(logits, top_k): Finds the k largest logit values and their positions.\n",
    "             - min_val: This is the value of the smallest logit in the top-k group.\n",
    "             - torch.where(...): This replaces all logits that are less than the min_val with -inf.\n",
    "               After softmax, these will have a probability of zero, effectively removing them from consideration.\n",
    "        \"\"\"\n",
    "        if top_k is not None:                #2\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        \"\"\"\n",
    "            * Apply Temperature Scaling and Sample:\n",
    "            * if temperature > 0.0: (Probabilistic Sampling)\n",
    "             - logits = logits / temperature: Adjusts the logits. \n",
    "               - Higher temperatures (>1) make the distribution flatter (more random). \n",
    "               - Lower temperatures (<1) make it sharper (more deterministic).\n",
    "             - torch.softmax(...): Converts the temperature-scaled logits into a probability distribution.\n",
    "             - torch.multinomial(...): Samples from this distribution.\n",
    "               - The model chooses a token randomly, but weighted by its probability. This is what introduces variety.\n",
    "\n",
    "            * else: (Greedy Decoding - the old method)\n",
    "             - torch.argmax(...): If temperature is 0, it falls back to the simple method.\n",
    "               - Always taking the token with the highest probability.\n",
    "               - This is deterministic and often repetitive.\n",
    "        \"\"\"\n",
    "        if temperature > 0.0:          \n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:    #4\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        \"\"\"\n",
    "            * Check for End-of-Sequence Token:\n",
    "             - Provides an early stopping mechanism. \n",
    "              - If the model generates a special \"end-of-sequence\" token (like <|endoftext|>), \n",
    "                the generation loop stops early, even if max_new_tokens hasn't been reached.\n",
    "              - This is useful for preventing the model from rambling.\n",
    "        \"\"\"\n",
    "        if idx_next == eos_id:           \n",
    "            break\n",
    "\n",
    "        \"\"\"\n",
    "            * Append the New Token and Continue:\n",
    "             - The newly generated token (idx_next) is appended to the existing sequence (idx).\n",
    "             - This new, longer sequence becomes the input for the next iteration of the loop.\n",
    "             - Finally, the fully generated sequence is returned.\n",
    "        \"\"\"\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6297b816-4dd4-4951-9da9-0cfcc2875aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " I would like to get. Iâ€™t, we because Iâ€™t know my\n"
     ]
    }
   ],
   "source": [
    "# Letâ€™s now see this new generate function in action:\n",
    "\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids('I would like to', tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7bc5434-0f98-4e99-bfe6-819ae5455d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    * This code saves the complete state of the training process to a file.\n",
    "    * It captures not just the model's learned weights, but also the optimizer's state, \n",
    "      allowing you to pause and resume training exactly where you left off, without any loss of progress.\n",
    "\n",
    "    * torch.save(): The PyTorch function that saves data to a file.\n",
    "    * 'model_and_optimizer.pth': The filename for the checkpoint.\n",
    "       The .pth extension is a conventional suffix for PyTorch model files.\n",
    "\n",
    "    * model.state_dict(): This method returns a dictionary that contains a full snapshot of the model's learnable parameters \n",
    "      (all the weights and biases of every layer: embeddings, attention weights, feed-forward network weights, etc.).\n",
    "\n",
    "    * optimizer.state_dict(): This method returns a dictionary that contains the internal state of the optimizer.\n",
    "    * The \"how\" to continue learning. For an optimizer like AdamW, this includes crucial information like:\n",
    "      - Momentum: The direction and velocity of the recent parameter updates.\n",
    "      - Second Moments: Adaptive learning rate information for each parameter.\n",
    "\"\"\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, \n",
    "    'model_and_optimizer.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7f8945-c038-4789-970e-38814757fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   * Then we can restore the model and optimizer states by first loading the saved data via torch.\n",
    "   * load and then using the load_state_dict method:\n",
    "\n",
    "    - torch.load(): The PyTorch function that loads data from a file.\n",
    "    - 'model_and_optimizer.pth': The filename of the checkpoint to load.\n",
    "    - map_location=device: This is a critical safety feature. \n",
    "      It ensures the tensors in the checkpoint are loaded onto the correct device (e.g., CPU or GPU).\n",
    "\n",
    "    * model = GPTModel(GPT_CONFIG_124M)\n",
    "     - You must first create a new model instance with the exact same architecture as the one that was saved.\n",
    "     - Why: The state_dict only contains the weights and parameters; it does not contain the code for the model's structure.\n",
    "\n",
    "    * model.load_state_dict(checkpoint['model_state_dict']):\n",
    "     - This accesses the part of the saved dictionary that contains all the model's weights.\n",
    "     - This method copies those saved weights into the new model's layers. \n",
    "     - After this, the model is no longer \"random\"; it has the knowledge it had when the checkpoint was saved.\n",
    "\n",
    "    * optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "     - Purpose: This is the key step for resuming training correctly. It restores the optimizer's internal state.\n",
    "     - What it restores: For AdamW, this includes momentum buffers and per-parameter learning rate adjustments.\n",
    "     - Without this, the optimizer would be \"reset,\" and continuing training would be much less stable and efficient, \n",
    "       as it would lose its \"memory\" of how it was previously updating the weights.\n",
    "\n",
    "    * model.train();\n",
    "     - Prepares the model to continue training.\n",
    "     - Reactivates training-specific behaviors like Dropout and Batch Normalization in training mode.\n",
    "\"\"\"\n",
    "\n",
    "checkpoint = torch.load('model_and_optimizer.pth', map_location=device) \n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.train();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
